{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c6fedd",
   "metadata": {},
   "source": [
    "# Cleaning Events data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85701093",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce727954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (1.5.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting seaborn\n",
      "  Downloading seaborn-0.12.0-py3-none-any.whl (285 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.1/285.1 kB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.9/295.9 kB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.8/960.8 kB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.0.5 cycler-0.11.0 fonttools-4.37.4 kiwisolver-1.4.4 matplotlib-3.6.0 pillow-9.2.0 seaborn-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fcfef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e6d18",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc40632",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('../sources/events.csv')\n",
    "registered = pd.read_csv('../sources/registered_in_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8f817",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c1f1d",
   "metadata": {},
   "source": [
    "**Cleaning events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f209f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useless columns\n",
    "\n",
    "TO_DROP_EVENTS = ['created_at','updated_at','organization_id']\n",
    "\n",
    "#Drop useless columns in events\n",
    "\n",
    "events.drop(TO_DROP_EVENTS, axis=1, inplace=True)\n",
    "\n",
    "#Drop null columns in events\n",
    "events.dropna(axis=1, how='all', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a5634",
   "metadata": {},
   "source": [
    "**Cleaning registered_in_events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc94f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_DROP_REGISTERED = ['id', 'created_at','updated_at','status']\n",
    "\n",
    "#Drop useless columns in registered_in_events\n",
    "\n",
    "registered.drop(TO_DROP_REGISTERED, axis=1, inplace=True)\n",
    "\n",
    "#Drop null columns in registered\n",
    "registered.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "#Drop null columns in registered\n",
    "registered.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e9e9c",
   "metadata": {},
   "source": [
    "**Joining both datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d486bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(registered, events, left_on=\"event_id\", right_on=\"id\").drop(['id','excerpt','eventbrite_sync_description','eventbrite_url','eventbrite_id','banner'], axis=1)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd66a4",
   "metadata": {},
   "source": [
    "**Cleaning merged dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23d3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['starting_at'] = merged['starting_at'].apply(pd.to_datetime)\n",
    "merged['ending_at'] = merged['ending_at'].apply(pd.to_datetime)\n",
    "merged['published_at'] = merged['published_at'].apply(pd.to_datetime)\n",
    "\n",
    "#Changing format\n",
    "merged['starting_at'] = merged['starting_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "merged['ending_at'] = merged['ending_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "merged['published_at'] = merged['published_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#Format change also changed the column type to object, so we need to convert it to datetime again \n",
    "merged['starting_at'] = merged['starting_at'].apply(pd.to_datetime)\n",
    "merged['ending_at'] = merged['ending_at'].apply(pd.to_datetime)\n",
    "merged['published_at'] = merged['published_at'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c076961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing commas in certain columns\n",
    "\n",
    "merged['tags'] = merged['tags'].str.replace(',', ' ')\n",
    "merged['description'] = merged['description'].str.replace(',', ' ')\n",
    "merged['title'] = merged['title'].str.replace(',', ' ')\n",
    "\n",
    "#Replacing nulls with 'undefined'\n",
    "\n",
    "merged = merged.replace(np.nan, 'Undefined', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dd6e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign language to events with missing info.\n",
    "\n",
    "merged['lang'] = np.where((merged['event_id'].isin([35,36,38,40,414,37,130,123,41,122,141,42,146,125,145,46,48,47,49,131,\n",
    "                                                    127,85,86,84,121,128,119,181,189,184,135,134,136,182,192,193,137,138,\n",
    "                                                    139,186,195,198,217,196,213,203,212,205,204,209,211,218,262,339,268,\n",
    "                                                    260,263,142,183,140,432,261,363,264,344,340,308,316])),'es', merged['lang'])\n",
    "\n",
    "merged['lang'] = np.where((merged['event_id'].isin([39,43,187,45,44,190,144,50,51,126,180,191,132,129,120,185,188,197,200,\n",
    "                                                    194,199,201,202,206,216,208,252,214,251,254,368,357,124,207,210,215])),'en', merged['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee74bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a small dataframe with event_id, tags and count of emails as (numer of attendies). From that dataframe use the next formula to make separation of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e20a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [{\n",
    "    \"tags\": \"tag1 tag2 tag9\",\n",
    "    \"attendies\": 23\n",
    "},\n",
    "{\n",
    "    \"tags\": \"tag2 tag1 tag5\",\n",
    "    \"attendies\": 57\n",
    "}]\n",
    "\n",
    "\n",
    "tags = {}\n",
    "for row in merged:\n",
    "    for tag in row['tags'].split(\" \"):\n",
    "        if tag not in tags:\n",
    "            tags[tag] = int(row['attendies'])\n",
    "        else:\n",
    "            tags[tag] += int(row['attendies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40beae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving joined dataset\n",
    "\n",
    "merged.to_csv('../output/events_and_attendies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1b001",
   "metadata": {},
   "source": [
    "**When joining with form_entries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(merged, forms[['email','lead_type', 'country','deal_status','won_at']],on='email', how='inner')\n",
    "final_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
